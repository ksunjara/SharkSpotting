{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SharkTesting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ksunjara/SharkSpotting/blob/master/pytorchfasterrcnn/SharkTesting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gA7ukMRm-yxO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "f5410828-3a27-4324-a8b2-5205afafc7f2"
      },
      "source": [
        "!pip install labelbox"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting labelbox\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/cd/e5443d2ef46ad7ac62e85444f9809b2cd0e5f34cfe33fb115385695f80c3/labelbox-2.4.9-py3-none-any.whl (48kB)\n",
            "\r\u001b[K     |██████▊                         | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 20kB 18.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 30kB 10.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 40kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses==0.7; python_version < \"3.7.0\" in /usr/local/lib/python3.6/dist-packages (from labelbox) (0.7)\n",
            "Collecting backoff==1.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/32/c5dd4f4b0746e9ec05ace2a5045c1fc375ae67ee94355344ad6c7005fd87/backoff-1.10.0-py2.py3-none-any.whl\n",
            "Collecting google-api-core>=1.22.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/3d/d7af13040ab5b259994a4434ff03d68084a994e709bc8afa4bee1235310e/google_api_core-1.23.0-py2.py3-none-any.whl (91kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 5.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.6/dist-packages (from labelbox) (2.23.0)\n",
            "Collecting ndjson==0.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/70/c9/04ba0056011ba96a58163ebfd666d8385300bd12da1afe661a5a147758d7/ndjson-0.3.1-py2.py3-none-any.whl\n",
            "Collecting backports-datetime-fromisoformat==1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/20/15/4bc39da78d00da480ff627398ad25770be1f0c3cf40ea9bc5e9030b441fb/backports-datetime-fromisoformat-1.0.0.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core>=1.22.1->labelbox) (3.12.4)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core>=1.22.1->labelbox) (2018.9)\n",
            "Collecting google-auth<2.0dev,>=1.21.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/60/81e68e70eea91ef05bb00bcdac243d67b61f826c65aaca6961de622dffd7/google_auth-1.23.0-py2.py3-none-any.whl (114kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 9.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core>=1.22.1->labelbox) (50.3.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core>=1.22.1->labelbox) (1.52.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core>=1.22.1->labelbox) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->labelbox) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->labelbox) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->labelbox) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->labelbox) (2020.6.20)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core>=1.22.1->labelbox) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core>=1.22.1->labelbox) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core>=1.22.1->labelbox) (0.2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.5\"->google-auth<2.0dev,>=1.21.1->google-api-core>=1.22.1->labelbox) (0.4.8)\n",
            "Building wheels for collected packages: backports-datetime-fromisoformat\n",
            "  Building wheel for backports-datetime-fromisoformat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for backports-datetime-fromisoformat: filename=backports_datetime_fromisoformat-1.0.0-cp36-cp36m-linux_x86_64.whl size=32334 sha256=307c0c2495dfb6dc9f7779caef8f3e44246d2c6a1b32669283c117842d3442e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/ca/6c/8b422f60f0660a8e23f081581fabbbbde5c4d0e2683f8050c0\n",
            "Successfully built backports-datetime-fromisoformat\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.17.2, but you'll have google-auth 1.23.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: backoff, google-auth, google-api-core, ndjson, backports-datetime-fromisoformat, labelbox\n",
            "  Found existing installation: google-auth 1.17.2\n",
            "    Uninstalling google-auth-1.17.2:\n",
            "      Successfully uninstalled google-auth-1.17.2\n",
            "  Found existing installation: google-api-core 1.16.0\n",
            "    Uninstalling google-api-core-1.16.0:\n",
            "      Successfully uninstalled google-api-core-1.16.0\n",
            "Successfully installed backoff-1.10.0 backports-datetime-fromisoformat-1.0.0 google-api-core-1.23.0 google-auth-1.23.0 labelbox-2.4.9 ndjson-0.3.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBHqUnj8-9Bt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fd32260-dbf4-47ed-9dbf-16b9f1ad2a96"
      },
      "source": [
        "!git clone https://github.com/pytorch/vision.git\n",
        "!cp vision/references/detection/*.py .\n",
        "from google.colab import drive\n",
        "drive.mount('drive')\n",
        "import torch\n",
        "import torchvision\n",
        "import math\n",
        "import time\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection.faster_rcnn import FasterRCNN\n",
        "import torchvision.models.detection.faster_rcnn\n",
        "from torchvision.models.detection.rpn import AnchorGenerator, RegionProposalNetwork, RPNHead\n",
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
        "from torchvision.models.detection.transform import GeneralizedRCNNTransform\n",
        "from torchvision.models.detection.roi_heads import RoIHeads\n",
        " \n",
        "import cv2\n",
        "import json\n",
        "from labelbox import Client\n",
        "import urllib.request\n",
        "from urllib.parse import urlparse\n",
        "import io\n",
        "from PIL import Image\n",
        "import PIL\n",
        "import requests\n",
        "import os\n",
        "from os import path\n",
        "import time\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "import numpy as np\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import pycocotools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 11287 (delta 14), reused 17 (delta 1), pack-reused 11237\u001b[K\n",
            "Receiving objects: 100% (11287/11287), 12.74 MiB | 20.20 MiB/s, done.\n",
            "Resolving deltas: 100% (7849/7849), done.\n",
            "Mounted at drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fKGN8jU_Ak8",
        "cellView": "form"
      },
      "source": [
        "#@title shark dataset and showboxes function\n",
        "class SharkDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self):\n",
        "        def retrieve_data(project_unique_id, api_key):\n",
        "            client = Client(api_key)\n",
        "            project = client.get_project(project_unique_id)\n",
        "            retrieve_url = project.export_labels()\n",
        "            with urllib.request.urlopen(retrieve_url) as url:\n",
        "                    response = url.read()\n",
        "                    data = json.loads(response)\n",
        "            return data\n",
        "        sharkprojectid = \"ckcgqorltvxoi08974xshx1wi\"\n",
        "        kathirapikey = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJja2NmeDFybDFuczE3MDczNnZicHpid2tvIiwib3JnYW5pemF0aW9uSWQiOiJja2NmeDFya2k1OGdkMDg5NmFybjFramN6IiwiYXBpS2V5SWQiOiJja2Q4Mm1kMm9pYXBjMDc1M2Nyczd3Z2t6IiwiaWF0IjoxNTk2MDY5NTg0LCJleHAiOjIyMjcyMjE1ODR9.O1p-NjON6i_p7BYTufXx3bFpfaopuPiUxb58fNRmYtY\"\n",
        "        self.objectmapping = {'juvenile_white_shark': 1 , 'surfer': 2, 'paddleboarder': 3, 'swimmer':4, 'wader': 5, 'leopard shark': 6, 'dolphin': 7, 'boat': 8, 'bodyboarder':9}\n",
        "        initialdata = retrieve_data(sharkprojectid, kathirapikey)\n",
        "        self.data = []\n",
        "        for i in initialdata:\n",
        "            ans = self.extract_boxes_labels(i)\n",
        "            if ans is None:\n",
        "                pass\n",
        "            else:\n",
        "                self.data.append(i)\n",
        "\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \"Returns the image (tensor), and target {boxes, labels}\"\n",
        "        target = {}\n",
        "\n",
        "        record = self.data[idx]\n",
        "        jpg_url = record['Labeled Data']\n",
        "        img = Image.open(urllib.request.urlopen(jpg_url))\n",
        "        img = torchvision.transforms.ToTensor()(img)\n",
        "\n",
        "        boxes, labels = self.extract_boxes_labels(record)\n",
        "        image_id = torch.tensor([idx])\n",
        "\n",
        "        #if boxes are empty\n",
        "        try:\n",
        "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "        except:\n",
        "            area = boxes\n",
        "\n",
        "        iscrowd = torch.zeros((len(boxes),), dtype=torch.int64)\n",
        "        target['boxes'] = boxes\n",
        "        target['labels'] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "        return (img, target)\n",
        "\n",
        "    \n",
        "    def extract_boxes_labels(self, record):\n",
        "        boxes = []\n",
        "        labels = []\n",
        "        \n",
        "        if 'objects' in record['Label']:\n",
        "            for i in record['Label']['objects']:\n",
        "                xmin = int(i['bbox']['left'])\n",
        "                ymin = int(i['bbox']['top'])\n",
        "                xmax = xmin + i['bbox']['width']\n",
        "                ymax = ymin + i['bbox']['height']\n",
        "                coors = [xmin, ymin, xmax, ymax]\n",
        "                boxes.append(coors)\n",
        "\n",
        "                if i['value'] == 'shark' or i['value'] == 'person':\n",
        "                    try:\n",
        "                        labels.append(self.objectmapping[self.get_nested_class(i)])\n",
        "                    except:\n",
        "                        return None\n",
        "                else:\n",
        "                    labels.append(self.objectmapping[i['value']])\n",
        "\n",
        "            labels = torch.tensor(labels)\n",
        "            boxes = torch.tensor(boxes)\n",
        "            return boxes, labels\n",
        "        else:\n",
        "            return None\n",
        "    \n",
        "    def get_nested_class(self, recordobject):\n",
        "        return recordobject['classifications'][0]['answer'][0]['value']\n",
        "\n",
        "\n",
        "def show_boxes(im,boxes):\n",
        "    im = im.permute(1, 2, 0)\n",
        "    pyplot.title('Test')\n",
        "    pyplot.imshow(im)\n",
        "    ax = pyplot.gca()\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box\n",
        "        width, height = x2 - x1, y2 - y1\n",
        "        rect = Rectangle((x1, y1), width, height, fill = False, color='red')\n",
        "        ax.add_patch(rect)\n",
        "    pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNSbi3ID-2x-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "91605207-217e-4baa-e978-f61d2f204961"
      },
      "source": [
        "#Make this into its own section \n",
        " \n",
        "#example of loading model from save file and running it on split frames located within current directory\n",
        " \n",
        "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        " \n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "num_classes = 12\n",
        " \n",
        "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "model.to(device)\n",
        " \n",
        "model.load_state_dict(torch.load(\"drive/My Drive/novemberfifteenth.pth\", map_location=device))\n",
        "\n",
        "label_colors = {\n",
        "    1 : \"red\",      #juvenile_white_shark\n",
        "    2 : \"#74f174\",  #surfer\n",
        "    3 : \"#eeab5d\",  #paddleboarder\n",
        "    4 : \"#f1f174\",  #swimmer\n",
        "    5 : \"#f1d274\",  #wader\n",
        "    6 : \"#74d2f1\",  #leopard shark\n",
        "    7 : \"#7474f1\",  #dolphin\n",
        "    8 : \"#95FF80\",  #boat\n",
        "    9 : \"408732\",    #bodyboarder\n",
        "    10 : \"blue\",\n",
        "    11 : \"blue\"\n",
        "}\n",
        "\n",
        "def show_boxes(im,boxes, labels):\n",
        "    im = im.permute(1, 2, 0)\n",
        "    pyplot.title('Test')\n",
        "    pyplot.imshow(im)\n",
        "    ax = pyplot.gca()\n",
        "    n=0\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box\n",
        "        width, height = x2 - x1, y2 - y1\n",
        "\n",
        "        rect = Rectangle((x1, y1), width, height, fill = False, color=label_colors.get(labels[n]))\n",
        "        ax.add_patch(rect)\n",
        "        n+=1\n",
        "    pyplot.show() \n",
        " \n",
        "ex = \"drive/My Drive/480-Shark-Project/exampleimages/exampleimages_\"\n",
        "\n",
        "class tst:\n",
        "    def __init__(self, label, items, image, boxes=[]):\n",
        "        self.label = label\n",
        "        self.items = items\n",
        "        self.img = ex+str(image)+\".jpg\"\n",
        "        self.boxes = boxes \n",
        "    def __len__(self):\n",
        "        return self.items\n",
        "     \n",
        "\n",
        "shark_tests = []\n",
        "\n",
        "shark_tests.append(tst(1, 1,1 ))\n",
        "\n",
        "\n",
        "# List containing tests for humans\n",
        "human_tests = []\n",
        "\n",
        "# adding tests to  test list\n",
        "# format: label to look for's #, number of items of that label in that response, and the example_image's number\n",
        "\n",
        "human_tests.append(tst(2, 0, 1))\n",
        "human_tests.append(tst(2, 0, 2))\n",
        "human_tests.append(tst(2, 0, 3))\n",
        "human_tests.append(tst(2, 0, 4))\n",
        "human_tests.append(tst(2, 0, 5))\n",
        "human_tests.append(tst(2, 0, 130))\n",
        "#human_tests.append(tst(2, 10, 131))\n",
        "#human_tests.append(tst(2, 10, 132))\n",
        "#human_tests.append(tst(2, 2, 133))\n",
        "#human_tests.append(tst(2, 2, 134))\n",
        "#human_tests.append(tst(2, 3, 135))\n",
        "human_tests.append(tst(2, 2, 136))\n",
        "human_tests.append(tst(2, 0, 137))\n",
        "human_tests.append(tst(2, 0, 138))\n",
        "human_tests.append(tst(2, 0, 139))\n",
        "human_tests.append(tst(2, 0, 141))\n",
        "human_tests.append(tst(2, 0, 142))\n",
        "human_tests.append(tst(2, 0, 143))\n",
        "\n",
        "# List containing tests for OnBeach\n",
        "beach_tests = []\n",
        "\n",
        "# adding tests to  test list\n",
        "# format: label to look for's #, number of items of that label in that response, and the example_image's number\n",
        "\n",
        "beach_tests.append(tst(11, 2, 1))\n",
        "beach_tests.append(tst(11, 2, 2))\n",
        "beach_tests.append(tst(11, 2, 3))\n",
        "beach_tests.append(tst(11, 1, 4))\n",
        "beach_tests.append(tst(11, 1, 5))\n",
        "\n",
        "beach_tests.append(tst(11, 0, 136))\n",
        "beach_tests.append(tst(11, 7, 137))\n",
        "beach_tests.append(tst(11, 6, 138))\n",
        "beach_tests.append(tst(11, 1, 139))\n",
        "beach_tests.append(tst(11, 2, 141))\n",
        "beach_tests.append(tst(11, 2, 142))\n",
        "beach_tests.append(tst(11, 1, 143))\n",
        "\n",
        "\n",
        "#beach_tests.append(tst(11, 10, 131))\n",
        "#beach_tests.append(tst(11, 10, 132))\n",
        "#beach_tests.append(tst(11, 2, 133))\n",
        "#beach_tests.append(tst(11, 2, 134))\n",
        "#beach_tests.append(tst(11, 3, 135))\n",
        "\n",
        "nwrong =0\n",
        "def test_label (label, test_lst,  check_boxes=False,box_threshold=5 ):\n",
        "    item_cor = []\n",
        "    item_wro = []\n",
        "    total = 0\n",
        "    avg_confid =0\n",
        "    n =1\n",
        "    nwrong=0\n",
        "    for test in test_lst:\n",
        "        \n",
        "        #Get labels and scores\n",
        "        image = Image.open(test.img)\n",
        "        image = torchvision.transforms.ToTensor()(image)\n",
        "        cudimage = image.cuda()\n",
        "        model.eval()\n",
        "        ans = model([cudimage])\n",
        "        keep = torchvision.ops.nms(ans[0]['boxes'], ans[0]['scores'], 0)\n",
        "        labels = ans[0]['labels'].tolist()\n",
        "        scores = ans[0]['scores'].tolist()\n",
        "\n",
        "        # uncomment for faster performance, or to not see the boxes\n",
        "        #show_boxes(image, ans[0]['boxes'][keep], labels)\n",
        "        #print(labels)\n",
        "\n",
        "        exists_in = [i for i in labels if i == test.label]\n",
        "\n",
        "        total+=test.items\n",
        "        if len(exists_in) > test.items:\n",
        "            nwrong+=  len(exists_in) - test.items;\n",
        "        if len(exists_in)< test.items:\n",
        "            item_wro.append((\"(Test \"+str(n)+\" # of Items missing:  \"+str(test.items-len(exists_in))+\") DNE\" ))\n",
        "        if len(exists_in) > 0:\n",
        "        # Go through each test item\n",
        "            cur_item =0\n",
        "            for i in range(len(labels)):\n",
        "                if  labels[i] == test.label:\n",
        "                    if cur_item+1 <= test.items:\n",
        "                        item_cor.append((\"(Test \"+str(n)+\" Item \"+str(test.label)+\") Score: \" + str(round(scores[i],3))))\n",
        "                        avg_confid += scores[i]\n",
        "                    else: \n",
        "                        item_wro.append((\"(Test \"+str(n)+\" Item \"+str(test.label)+\") TOOMANY\" ))                    \n",
        "                    cur_item+=1\n",
        "        n+=1\n",
        "    print( \"Percentage of Correct Labels: \" + str(round(len(item_cor)/(nwrong+total)*100,2) ) + \"%\")\n",
        "    if( len(item_cor) >0):\n",
        "        print( \"Average Confidence of Labels: \" + str(round(avg_confid/len(item_cor)*100,2)) + \"%\")\n",
        "    else:\n",
        "        print( \"Average Confidence of Labels: 0% none found\")\n",
        "    \n",
        "    print(\"Incorrect Entries:\" , item_wro)\n",
        "    print(\"Correct Entries:\", item_cor)\n",
        "\n",
        "print(\"Results of Shark test: \")\n",
        "test_label(1,shark_tests)\n",
        "print(\"\\nResults of Surfer test: \")\n",
        "test_label(2, human_tests)\n",
        "print(\"\\nResults of OnBeach test: \")\n",
        "test_label(11, beach_tests)\n",
        "'''\n",
        "for i in range(136,143):\n",
        "    image = Image.open(ex+str(i)+\".jpg\")\n",
        "    image = torchvision.transforms.ToTensor()(image)\n",
        "    cudimage = image.cuda()\n",
        "    print(image.size())\n",
        "    model.eval()\n",
        "    ans = model([cudimage])\n",
        "    keep = torchvision.ops.nms(ans[0]['boxes'], ans[0]['scores'], 0)\n",
        "#    print(ans[0])\n",
        "    labels = ans[0]['labels'].tolist()\n",
        "    print(labels)\n",
        "    show_boxes(image, ans[0]['boxes'][keep], labels)\n",
        "'''\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results of Shark test: \n",
            "Percentage of Correct Labels: 100.0%\n",
            "Average Confidence of Labels: 93.63%\n",
            "Incorrect Entries: []\n",
            "Correct Entries: ['(Test 1 Item 1) Score: 0.936']\n",
            "\n",
            "Results of Surfer test: \n",
            "Percentage of Correct Labels: 33.33%\n",
            "Average Confidence of Labels: 98.48%\n",
            "Incorrect Entries: ['(Test 6 Item 2) TOOMANY', '(Test 6 Item 2) TOOMANY', '(Test 6 Item 2) TOOMANY', '(Test 9 Item 2) TOOMANY']\n",
            "Correct Entries: ['(Test 7 Item 2) Score: 0.992', '(Test 7 Item 2) Score: 0.978']\n",
            "\n",
            "Results of OnBeach test: \n",
            "Percentage of Correct Labels: 43.24%\n",
            "Average Confidence of Labels: 46.66%\n",
            "Incorrect Entries: ['(Test 1 # of Items missing:  2) DNE', '(Test 2 # of Items missing:  2) DNE', '(Test 3 # of Items missing:  2) DNE', '(Test 4 # of Items missing:  1) DNE', '(Test 5 # of Items missing:  1) DNE', '(Test 7 Item 11) TOOMANY', '(Test 7 Item 11) TOOMANY', '(Test 7 Item 11) TOOMANY', '(Test 7 Item 11) TOOMANY', '(Test 7 Item 11) TOOMANY', '(Test 7 Item 11) TOOMANY', '(Test 7 Item 11) TOOMANY', '(Test 8 Item 11) TOOMANY', '(Test 8 Item 11) TOOMANY', '(Test 9 # of Items missing:  1) DNE', '(Test 11 # of Items missing:  2) DNE', '(Test 12 Item 11) TOOMANY']\n",
            "Correct Entries: ['(Test 7 Item 11) Score: 0.939', '(Test 7 Item 11) Score: 0.901', '(Test 7 Item 11) Score: 0.761', '(Test 7 Item 11) Score: 0.611', '(Test 7 Item 11) Score: 0.59', '(Test 7 Item 11) Score: 0.519', '(Test 7 Item 11) Score: 0.269', '(Test 8 Item 11) Score: 0.945', '(Test 8 Item 11) Score: 0.135', '(Test 8 Item 11) Score: 0.126', '(Test 8 Item 11) Score: 0.122', '(Test 8 Item 11) Score: 0.098', '(Test 8 Item 11) Score: 0.063', '(Test 10 Item 11) Score: 0.596', '(Test 10 Item 11) Score: 0.067', '(Test 12 Item 11) Score: 0.723']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nfor i in range(136,143):\\n    image = Image.open(ex+str(i)+\".jpg\")\\n    image = torchvision.transforms.ToTensor()(image)\\n    cudimage = image.cuda()\\n    print(image.size())\\n    model.eval()\\n    ans = model([cudimage])\\n    keep = torchvision.ops.nms(ans[0][\\'boxes\\'], ans[0][\\'scores\\'], 0)\\n#    print(ans[0])\\n    labels = ans[0][\\'labels\\'].tolist()\\n    print(labels)\\n    show_boxes(image, ans[0][\\'boxes\\'][keep], labels)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcicGGHD75l6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "5fe0c8a7-92fd-49cb-c84f-70c4bac526fd"
      },
      "source": [
        "for i in range(1,79):\n",
        "    image = Image.open(ex+str(i)+\".jpg\")\n",
        "    image = torchvision.transforms.ToTensor()(image)\n",
        "    cudimage = image.cuda()\n",
        "    print(image.size())\n",
        "    model.eval()\n",
        "    ans = model([cudimage])\n",
        "    keep = torchvision.ops.nms(ans[0]['boxes'], ans[0]['scores'], 0)\n",
        "    print(ans[0])\n",
        "    show_boxes(image, ans[0]['boxes'][keep])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2160, 3840])\n",
            "{'boxes': tensor([[1434.8828,   42.4789, 1490.7393,  125.8941]], device='cuda:0',\n",
            "       grad_fn=<StackBackward>), 'labels': tensor([1], device='cuda:0'), 'scores': tensor([0.9363], device='cuda:0', grad_fn=<IndexBackward>)}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-e7b6df2c5516>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'scores'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mshow_boxes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'boxes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: show_boxes() missing 1 required positional argument: 'labels'"
          ]
        }
      ]
    }
  ]
}